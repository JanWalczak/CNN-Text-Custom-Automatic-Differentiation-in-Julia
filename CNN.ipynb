{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e38d5f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (43.04s)  Train: (l 0.5212, a 0.7291)  Test: (l 0.3793, a 0.8370)\n",
      "Epoch 2 (13.40s)  Train: (l 0.3267, a 0.8632)  Test: (l 0.3223, a 0.8690)\n",
      "Epoch 3 (13.34s)  Train: (l 0.2513, a 0.8988)  Test: (l 0.3117, a 0.8731)\n",
      "Epoch 4 (13.37s)  Train: (l 0.1957, a 0.9260)  Test: (l 0.3190, a 0.8739)\n",
      "Epoch 5 (13.35s)  Train: (l 0.1458, a 0.9497)  Test: (l 0.3359, a 0.8731)\n"
     ]
    }
   ],
   "source": [
    "using JLD2, Random, Statistics, Printf\n",
    "include(\"NETWORK.jl\")\n",
    "using .NETWORK\n",
    "using BenchmarkTools\n",
    "\n",
    "datapath = \"../Reference/CNN/CNN/data/imdb_dataset_prepared.jld2\"\n",
    "X_train = load(datapath, \"X_train\") \n",
    "y_train = load(datapath, \"y_train\")\n",
    "X_test = load(datapath, \"X_test\") \n",
    "y_test = load(datapath, \"y_test\") \n",
    "embeddings = load(datapath, \"embeddings\") \n",
    "vocab = load(datapath, \"vocab\")\n",
    "\n",
    "embedding_dim = size(embeddings, 1) \n",
    "\n",
    "X_train = Float32.(X_train);\n",
    "X_test = Float32.(X_test);\n",
    "\n",
    "y_train = Float32.(y_train);\n",
    "y_train = vec(y_train);\n",
    "\n",
    "y_test = Float32.(y_test)\n",
    "y_test = vec(y_test);\n",
    "\n",
    "model = NETWORK.Chain(\n",
    "    NETWORK.Embedding(length(vocab), embedding_dim),\n",
    "    NETWORK.Conv1D(embedding_dim, 8; kernel=3, activation=NETWORK.relu),\n",
    "    NETWORK.MaxPool1D(8),\n",
    "    NETWORK.Flatten(), \n",
    "    NETWORK.Dense(128, 1, NETWORK.sigma)\n",
    ")\n",
    "\n",
    "embeddings = Float32.(embeddings)\n",
    "model.layers[1].weight.value .= embeddings\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 64\n",
    "learning_rate = 0.001f0\n",
    "\n",
    "opt = NETWORK.AdamOptimizer(model, lr=learning_rate) \n",
    "test_trainer = NETWORK.Trainer(model, X_test, batch_size)\n",
    "train_trainer = NETWORK.Trainer(model, X_train, batch_size)\n",
    "# loader = NETWORK.DataLoader((X_train, y_train); batchsize=64, shuffle=true, prefetch_epochs=5)\n",
    "# loader = NETWORK.SimpleLoader(X_train,y_train; batchsize=64, shuffle=true)\n",
    "\n",
    "for epoch in 1:epochs\n",
    "    # GC.gc()\n",
    "    # stats = @allocated begin\n",
    "\n",
    "    total_loss = 0f0\n",
    "    total_acc  = 0f0\n",
    "    num_samples = 0\n",
    "\n",
    "    t = @elapsed begin\n",
    "        # for (x, y) in loader\n",
    "        #     batch_loss, batch_acc = NETWORK.train!(train_trainer, model, x, y, opt, batch_size)\n",
    "        #     total_loss += batch_loss\n",
    "        #     total_acc  += batch_acc\n",
    "        #     num_samples += 1\n",
    "        # end\n",
    "        train_loss, train_acc = NETWORK.train!(train_trainer, model, X_train, y_train, opt; batch_size = batch_size)\n",
    "        test_loss, test_acc = NETWORK.loss(test_trainer, X_test, y_test, batch_size)\n",
    "    end\n",
    "    # end\n",
    "    # train_loss = total_loss / num_samples\n",
    "    # train_acc = total_acc / (num_samples * batch_size)\n",
    "    @printf(\"Epoch %d (%.2fs)  Train: (l %.4f, a %.4f)  Test: (l %.4f, a %.4f)\\n\",\n",
    "        epoch, t, train_loss, train_acc, test_loss, test_acc)\n",
    "    # println(\"Allocations per epoch: $(round(stats / 1_048_576, digits=2)) MB\")\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.4",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
